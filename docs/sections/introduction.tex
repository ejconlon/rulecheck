\section{Introduction}

Optimizing compilers employ a number of techniques that transform code to yield
the same result with better runtime characteristics. For example, a compiler may
choose to replace the statement \texttt{y = x * 8;} with the more efficient,
equivalent version \texttt{y = x << 3}. Typically, these optimizations are
baked-in to the compiler; in other words, the compiler can only apply
transformations based on the semantics of operations built into the language
itself.

This limitation prevents the compiler from performing any higher-level
optimizations that require domain-specific information. For example, consider a
user-defined function \texttt{sum :: [Int] -> Int} that computes the sum of a
list of numbers. The expression \texttt{sum [1..limit]}, which computes the sum
of the numbers from 1 to \texttt{limit}, could in principle be optimized to
\texttt{(limit * (limit + 1) / 2)}. However, the compiler will not be able to
identify such an optimization, because \texttt{sum} is not built-in to the
language.

To support such optimizations, the Haskell programming language (as implemented
in the Glasgow Haskell Compiler, GHC) allows library authors to implement their
own compile-time optimizations in the form of rewrite rules. For example, the
above optimization could be enabled by adding the following annotation:\\
\texttt{\{-\# RULES forall n. sum [1..n] = n * (n+1)/2 \#-\}},\\
which instructs GHC to replace any instances of \texttt{sum [1..n]} with
\texttt{n * (n+1)/2} (where \texttt{n} is an arbitrary Haskell expression).

Rewrite rules are prevalent in the Haskell ecosystem. Many common low-level
libraries (like \texttt{vector}, \texttt{text}, and \texttt{bytestring}) make
heavy use of rewrite rules to eliminate redundant transformations, exposing
high-level interfaces with excellent runtime characteristics.
\cite{coutts2007stream, chakravarty2002approach, chakravarty2007data,
shortcutwiki}

However, although the rules themselves are type-checked, the compiler makes no
effort to ensure that they define sensible replacements. The GHC User's Guide
highlights the danger: ``GHC makes absolutely no attempt to verify that the LHS
and RHS of a rule have the same meaning. That is undecidable in general, and
infeasible in most interesting cases. The responsibility is entirely the
programmer's!'' \cite{userguide}.

As implemented, rewrite rules are a high-risk language feature: incorrect
statements can result in bugs that are difficult to understand due to the early
and automatic application of rewrites, as well as the interaction between rules.
Furthermore, rewrite rules themselves exists as annotations in the source code,
and are not, strictly speaking, Haskell code themselves. Therefore, rewrite
rules cannot be tested directly (for example, in unit tests).

Despite the importance of rewrite rules in the Haskell ecosystem, it is not
clear how many of the rewrite rules in Haskell libraries are correct, or even
how to test them. Therefore, we built \Rulecheck, a tool for automatic testing
of Haskell rewrite rules. \Rulecheck takes a Haskell library as input, and
generates a test suite containing a property-based test for each rewrite rule in
the library. A test failure in the generated suite indicates that application of
the corresponding rewrite rule can result in change in program behaviour, and
therefore the rule may be incorrect. We evaluated \Rulecheck on several packages
from \Hackage and found several instances where rule application can change
program behaviour.

We describe the methodology of \Rulecheck in \secref{methodology}. In
\secref{implementation} we describe the implementation of the tool; we present
evaluation results in \secref{evaluation}.
